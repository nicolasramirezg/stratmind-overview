Given the following subtask:

Subtask:
"${subtask}"

In the following context:

Root Task Title: ${root_task_title}
Area: ${area_name}
Area Description: ${area_description}

Existing sibling subtasks for this parent (do not duplicate these): ${existing_sibling_titles}

Analyze and determine if the subtask can be executed by a single agent.
Focus exclusively on the provided subtask. Do not consider or reference sibling subtasks or the overall area. 
If you propose refined subtasks, ensure they do not duplicate or overlap with any existing subtasks already defined for the parent task. 
Only refine if the subtask is ambiguous, overly broad, or involves multiple distinct decisions.

Return your analysis using exactly ONE of the following formats:

If the subtask is already sufficiently actionable and does NOT need further refinement, respond with ONLY this line (no extra text):

NO_REFINEMENT_NEEDED

If the subtask needs to be refined, respond with one or more blocks in this format (no extra text before, between, or after blocks):

---
Title: <short title>
Description: <description>
Execution_type: <llm|external_api|mcp|manual|...>
Expected_output: <expected output>
Dependencies: <comma-separated titles of other refined subtasks that must be completed first, or 'None'>
---


- If the subtask can be fully completed using only the information and reasoning available to the LLM (i.e., it does not require access to real-time data, external systems, APIs, or human intervention), set 'Execution_type' to 'llm'.
- If the subtask requires information or actions that are not accessible to the LLM (such as real-world data, external APIs, databases, or manual steps), specify the appropriate 'Execution_type' (e.g., 'external_api', 'mcp', 'manual', etc.).
Be precise: Only use 'llm' if the subtask can be solved entirely by the language model without any external input or action.

Do not include any explanations, comments, or extra text beyond these options.